{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapath = './iith-dl-contest-2024/train/train'\n",
    "train_data = datasets.ImageFolder(root=train_datapath, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# # how to access the train data\n",
    "# for i, (data, target) in enumerate(train_loader):\n",
    "#     print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "n01443537\n"
     ]
    }
   ],
   "source": [
    "# create a map for the lables corrosponds to the folder names\n",
    "label_map = train_data.class_to_idx\n",
    "print(label_map['n01443537'])\n",
    "\n",
    "# create a map for the folder names corrosponds to the lables\n",
    "label_map = dict((v,k) for k,v in label_map.items())\n",
    "print(label_map[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28589128\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# ResNet-18 model\n",
    "# model = models.resnet18(weights=None).to(device)\n",
    "model=models.convnext_tiny(weights=None).to(device)\n",
    "\n",
    "# # Initialize the weights using normal initialization\n",
    "# def normal_weights_init(m):\n",
    "#     if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "#         init.normal_(m.weight, mean=0, std=0.01)\n",
    "#         if m.bias is not None:\n",
    "#             init.constant_(m.bias, 0)\n",
    "\n",
    "# # Apply normal initialization to the model\n",
    "# model.apply(normal_weights_init)\n",
    "\n",
    "# printing the number of parameters\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CUDA is available. GPU detected.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU detected.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. CPU will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the test data accuracy\n",
    "test_datapath = './iith-dl-contest-2024/test' # this folder itself contains images\n",
    "\n",
    "# read all the images in test_datapath\n",
    "test_data = datasets.ImageFolder(root=test_datapath, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the predictions of test data in a list\n",
    "def return_predictons(model, test_loader):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # move the images and labels to GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model.forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the images names in a list for eg 1.jpeg, 2.jpeg, 3.jpeg\n",
    "\n",
    "def return_images_names(test_data):\n",
    "    images_names = []\n",
    "    for i in range(len(test_data)):\n",
    "        images_names.append(test_data.imgs[i][0].split('/')[-1])\n",
    "    return images_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the images names and the predictions in a csv file with ID and Category as the column names\n",
    "# import csv\n",
    "# with open('resnet34_expoch.csv', mode='w') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['ID', 'Category'])\n",
    "#     for i in range(len(images_names)):\n",
    "#         writer.writerow([images_names[i], label_map[predictions[i].item()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_for_each_epoch(model, test_loader, test_data, epoch):\n",
    "    predictions = return_predictons(model, test_loader)\n",
    "    images_names = return_images_names(test_data)\n",
    "    with open('./teja/resnet34_epoch'+str(epoch)+'.csv', mode='w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['ID', 'Category'])\n",
    "        for i in range(len(images_names)):\n",
    "            writer.writerow([images_names[i], label_map[predictions[i].item()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=2):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "        \n",
    "        # Print the running loss and accuracy\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Accuracy: {epoch_accuracy}')\n",
    "        print(f'Finished epoch {epoch}.')\n",
    "        \n",
    "        generate_csv_for_each_epoch(model, test_loader, test_data, epoch)\n",
    "        print('CSV file generated for epoch', epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_load_model_weights(model, filename):\n",
    "    # Save model weights\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f\"Model weights saved to '{filename}'\")\n",
    "\n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    print(f\"Model weights loaded from '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.334951640114071, Accuracy: 0.15096923076923077\n",
      "Finished epoch 0.\n",
      "CSV file generated for epoch 0\n",
      "Epoch 2, Loss: 2.9096211796905114, Accuracy: 0.2366769230769231\n",
      "Finished epoch 1.\n",
      "CSV file generated for epoch 1\n",
      "Epoch 3, Loss: 2.7025648049247546, Accuracy: 0.2828769230769231\n",
      "Finished epoch 2.\n",
      "CSV file generated for epoch 2\n",
      "Epoch 4, Loss: 2.503279205030344, Accuracy: 0.32703076923076924\n",
      "Finished epoch 3.\n",
      "CSV file generated for epoch 3\n",
      "Epoch 5, Loss: 2.28893754220619, Accuracy: 0.37901538461538464\n",
      "Finished epoch 4.\n",
      "CSV file generated for epoch 4\n",
      "Epoch 6, Loss: 2.0739939156479723, Accuracy: 0.4276615384615385\n",
      "Finished epoch 5.\n",
      "CSV file generated for epoch 5\n",
      "Epoch 7, Loss: 1.8419434500960854, Accuracy: 0.4816923076923077\n",
      "Finished epoch 6.\n",
      "CSV file generated for epoch 6\n",
      "Epoch 8, Loss: 1.5626796161330592, Accuracy: 0.5475230769230769\n",
      "Finished epoch 7.\n",
      "CSV file generated for epoch 7\n",
      "Epoch 9, Loss: 1.2259568725602599, Accuracy: 0.636676923076923\n",
      "Finished epoch 8.\n",
      "CSV file generated for epoch 8\n",
      "Epoch 10, Loss: 0.8587359444377577, Accuracy: 0.7376615384615385\n",
      "Finished epoch 9.\n",
      "CSV file generated for epoch 9\n",
      "Epoch 11, Loss: 0.5823102278092246, Accuracy: 0.8156\n",
      "Finished epoch 10.\n",
      "CSV file generated for epoch 10\n",
      "Epoch 12, Loss: 0.43288331314752715, Accuracy: 0.8624307692307692\n",
      "Finished epoch 11.\n",
      "CSV file generated for epoch 11\n",
      "Epoch 13, Loss: 0.3472333959556793, Accuracy: 0.8900615384615385\n",
      "Finished epoch 12.\n",
      "CSV file generated for epoch 12\n",
      "Epoch 14, Loss: 0.29654682977180047, Accuracy: 0.9058307692307692\n",
      "Finished epoch 13.\n",
      "CSV file generated for epoch 13\n",
      "Epoch 15, Loss: 0.27031979746988233, Accuracy: 0.9155692307692308\n",
      "Finished epoch 14.\n",
      "CSV file generated for epoch 14\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, num_epochs=15)\n",
    "# save_and_load_model_weights(model, 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
